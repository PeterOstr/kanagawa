{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-17T15:47:22.911346100Z",
     "start_time": "2023-12-17T15:47:17.971472100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Abstract\n",
    "In this notebook we will consider 3 ways of hyperparameters optimization:\n",
    "\n",
    "- by Grid Search\n",
    "- by Random Search\n",
    "- by Optuna optimization module"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20b0c961035d0dc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For testing purposes we will use the Diabetes prediction dataset from Kaggle (https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset).\n",
    "\n",
    "About the Dataset\n",
    "\n",
    "The diabetes_prediction_dataset.csv file contains medical and demographic data of patients along with their diabetes status, whether positive or negative. It consists of various features such as age, gender, body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level. The Dataset can be utilized to construct machine learning models that can predict the likelihood of diabetes in patients based on their medical history and demographic details."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a3487e4e3a393d6"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n0      Female  80.0             0              1           never  25.19   \n1      Female  54.0             0              0         No Info  27.32   \n2        Male  28.0             0              0           never  27.32   \n3      Female  36.0             0              0         current  23.45   \n4        Male  76.0             1              1         current  20.14   \n...       ...   ...           ...            ...             ...    ...   \n99995  Female  80.0             0              0         No Info  27.32   \n99996  Female   2.0             0              0         No Info  17.37   \n99997    Male  66.0             0              0          former  27.83   \n99998  Female  24.0             0              0           never  35.42   \n99999  Female  57.0             0              0         current  22.43   \n\n       HbA1c_level  blood_glucose_level  diabetes  \n0              6.6                  140         0  \n1              6.6                   80         0  \n2              5.7                  158         0  \n3              5.0                  155         0  \n4              4.8                  155         0  \n...            ...                  ...       ...  \n99995          6.2                   90         0  \n99996          6.5                  100         0  \n99997          5.7                  155         0  \n99998          4.0                  100         0  \n99999          6.6                   90         0  \n\n[100000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>smoking_history</th>\n      <th>bmi</th>\n      <th>HbA1c_level</th>\n      <th>blood_glucose_level</th>\n      <th>diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>never</td>\n      <td>25.19</td>\n      <td>6.6</td>\n      <td>140</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>27.32</td>\n      <td>6.6</td>\n      <td>80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.32</td>\n      <td>5.7</td>\n      <td>158</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>current</td>\n      <td>23.45</td>\n      <td>5.0</td>\n      <td>155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>76.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>current</td>\n      <td>20.14</td>\n      <td>4.8</td>\n      <td>155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>Female</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>27.32</td>\n      <td>6.2</td>\n      <td>90</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>Female</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>17.37</td>\n      <td>6.5</td>\n      <td>100</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>Male</td>\n      <td>66.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>former</td>\n      <td>27.83</td>\n      <td>5.7</td>\n      <td>155</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>Female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>35.42</td>\n      <td>4.0</td>\n      <td>100</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>Female</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>current</td>\n      <td>22.43</td>\n      <td>6.6</td>\n      <td>90</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:02:22.452011800Z",
     "start_time": "2023-12-12T23:02:22.314013200Z"
    }
   },
   "id": "2cf305ee855f7af0"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T23:02:22.512010400Z",
     "start_time": "2023-12-12T23:02:22.457013100Z"
    }
   },
   "id": "4047357ca6b713b3"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "X = data.drop('diabetes',axis=1)\n",
    "y = data['diabetes']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:58:13.486138600Z",
     "start_time": "2023-12-12T22:58:13.419140700Z"
    }
   },
   "id": "972aee9a2512c05c"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y,train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:59:22.990617500Z",
     "start_time": "2023-12-12T22:59:22.934137600Z"
    }
   },
   "id": "5c757f7cf54ee85"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n32510  Female  80.0             0              0         No Info  27.32   \n62071    Male  74.0             1              0           never  27.32   \n96665  Female  20.0             0              0           never  20.37   \n43848    Male  27.0             0              0         No Info  20.93   \n47377  Female  30.0             0              0           never  27.82   \n...       ...   ...           ...            ...             ...    ...   \n92401  Female  74.0             0              0           never  28.12   \n1080     Male   3.0             0              0         No Info  14.31   \n13032  Female  63.0             0              0          former  33.90   \n46709    Male  17.0             0              0         No Info  27.86   \n29749    Male   2.0             0              0         No Info  18.31   \n\n       HbA1c_level  blood_glucose_level  \n32510          4.8                   80  \n62071          8.8                  200  \n96665          6.6                   90  \n43848          5.8                  200  \n47377          5.0                   80  \n...            ...                  ...  \n92401          8.8                  240  \n1080           6.6                   80  \n13032          8.2                  240  \n46709          6.0                   85  \n29749          6.6                   90  \n\n[70000 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>age</th>\n      <th>hypertension</th>\n      <th>heart_disease</th>\n      <th>smoking_history</th>\n      <th>bmi</th>\n      <th>HbA1c_level</th>\n      <th>blood_glucose_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32510</th>\n      <td>Female</td>\n      <td>80.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>27.32</td>\n      <td>4.8</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>62071</th>\n      <td>Male</td>\n      <td>74.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.32</td>\n      <td>8.8</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>96665</th>\n      <td>Female</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>20.37</td>\n      <td>6.6</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>43848</th>\n      <td>Male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>20.93</td>\n      <td>5.8</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>47377</th>\n      <td>Female</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>27.82</td>\n      <td>5.0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92401</th>\n      <td>Female</td>\n      <td>74.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>never</td>\n      <td>28.12</td>\n      <td>8.8</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>1080</th>\n      <td>Male</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>14.31</td>\n      <td>6.6</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>13032</th>\n      <td>Female</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>former</td>\n      <td>33.90</td>\n      <td>8.2</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>46709</th>\n      <td>Male</td>\n      <td>17.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>27.86</td>\n      <td>6.0</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>29749</th>\n      <td>Male</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Info</td>\n      <td>18.31</td>\n      <td>6.6</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n<p>70000 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:59:23.260616300Z",
     "start_time": "2023-12-12T22:59:23.230619500Z"
    }
   },
   "id": "f5bcd085336c9c4f"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "categorical_features = ['gender','hypertension','heart_disease','smoking_history']\n",
    "\n",
    "numeric_features = [i for i in X_train.columns if i not in categorical_features]\n",
    "\n",
    "\n",
    "# numeric data pipeline\n",
    "pipe_num = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('power_tr', PowerTransformer()),\n",
    "    ('scaler', StandardScaler()) ])\n",
    "\n",
    "# cat data pipeline\n",
    "pipe_cat = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='unknown')),\n",
    "    ('encoding', OneHotEncoder(sparse_output=False, handle_unknown='ignore')) ])\n",
    "\n",
    "# column transformer\n",
    "ct = ColumnTransformer([\n",
    "    ('pipe_num', pipe_num, numeric_features),\n",
    "    ('pipe_cat', pipe_cat, categorical_features) ])\n",
    "\n",
    "#full pipeline\n",
    "pipe = Pipeline([\n",
    "    ('column_transformer', ct),\n",
    "    ('model', xgb.XGBRegressor()),  # It denotes the fraction of observations to be randomly samples for each tree. \n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:59:23.379614600Z",
     "start_time": "2023-12-12T22:59:23.325649300Z"
    }
   },
   "id": "21fea40c164ff12b"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T22:59:23.489614300Z",
     "start_time": "2023-12-12T22:59:23.431616400Z"
    }
   },
   "id": "312d4b9d04a0e2a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.Hyperparameters of XG_Boost\n",
    "\n",
    "#### 1. eta\n",
    "\n",
    "eta [default=0.3, alias: learning_rate]\n",
    "\n",
    "It is analogous to learning rate in GBM.\n",
    "It is the step size shrinkage used in update to prevent overfitting.\n",
    "After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "It makes the model more robust by shrinking the weights on each step.\n",
    "range : [0,1]\n",
    "Typical final values : 0.01-0.2.\n",
    "\n",
    "#### 2.  gamma\n",
    "\n",
    "gamma [default=0, alias: min_split_loss]\n",
    "\n",
    "A node is split only when the resulting split gives a positive reduction in the loss function.\n",
    "Gamma specifies the minimum loss reduction required to make a split.\n",
    "It makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "The larger gamma is, the more conservative the algorithm will be.\n",
    "Range: [0,∞]\n",
    "\n",
    "\n",
    "\n",
    "#### 3. max_depth\n",
    "\n",
    "max_depth [default=6]\n",
    "\n",
    "The maximum depth of a tree, same as GBM.\n",
    "It is used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "Increasing this value will make the model more complex and more likely to overfit.\n",
    "The value 0 is only accepted in lossguided growing policy when tree_method is set as hist and it indicates no limit on depth.\n",
    "We should be careful when setting large value of max_depth because XGBoost aggressively consumes memory when training a deep tree.\n",
    "range: [0,∞] (0 is only accepted in lossguided growing policy when tree_method is set as hist.\n",
    "Should be tuned using CV.\n",
    "Typical values: 3-10\n",
    "\n",
    "#### 4. min_child_weight\n",
    "\n",
    "min_child_weight [default=1]\n",
    "\n",
    "It defines the minimum sum of weights of all observations required in a child.\n",
    "This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n",
    "It is used to control over-fitting.\n",
    "Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "    Too high values can lead to under-fitting.\n",
    "Hence, it should be tuned using CV.\n",
    "The larger min_child_weight is, the more conservative the algorithm will be.\n",
    "range: [0,∞]\n",
    "\n",
    "#### 5. max_delta_step\n",
    "\n",
    "max_delta_step [default=0]\n",
    "\n",
    "In maximum delta step we allow each tree’s weight estimation to be.\n",
    "If the value is set to 0, it means there is no constraint.\n",
    "If it is set to a positive value, it can help making the update step more conservative.\n",
    "Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n",
    "Set it to value of 1-10 might help control the update.\n",
    "range: [0,∞]\n",
    "\n",
    "#### 6. subsample\n",
    "\n",
    "subsample [default=1]\n",
    "\n",
    "It denotes the fraction of observations to be randomly samples for each tree.\n",
    "    Subsample ratio of the training instances.\n",
    "Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. - This will prevent overfitting.\n",
    "Subsampling will occur once in every boosting iteration.\n",
    "Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "Typical values: 0.5-1\n",
    "range: (0,1]\n",
    "\n",
    "\n",
    "#### 7. colsample_bytree, colsample_bylevel, colsample_bynode\n",
    "Table of Contents\n",
    "\n",
    "colsample_bytree, colsample_bylevel, colsample_bynode [default=1]\n",
    "\n",
    "This is a family of parameters for subsampling of columns.\n",
    "\n",
    "All colsample_by parameters have a range of (0, 1], the default value of 1, and specify the fraction of columns to be subsampled.\n",
    "\n",
    "colsample_bytree is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "\n",
    "colsample_bylevel is the subsample ratio of columns for each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree.\n",
    "\n",
    "colsample_bynode is the subsample ratio of columns for each node (split). Subsampling occurs once every time a new split is evaluated. Columns are subsampled from the set of columns chosen for the current level.\n",
    "\n",
    "colsample_by* parameters work cumulatively. For instance, the combination {'colsample_bytree':0.5, 'colsample_bylevel':0.5, 'colsample_bynode':0.5} with 64 features will leave 8 features to choose from at each split.\n",
    "\n",
    "#### 8. lambda\n",
    "\n",
    "        lambda [default=1, alias: reg_lambda]\n",
    "\n",
    "L2 regularization term on weights (analogous to Ridge regression).\n",
    "This is used to handle the regularization part of XGBoost.\n",
    "Increasing this value will make model more conservative.\n",
    "\n",
    "\n",
    "#### 9. alpha\n",
    "\n",
    "alpha [default=0, alias: reg_alpha]\n",
    "\n",
    "L1 regularization term on weights (analogous to Lasso regression).\n",
    "It can be used in case of very high dimensionality so that the algorithm runs faster when implemented.\n",
    "Increasing this value will make model more conservative.\n",
    "\n",
    "\n",
    "#### 10. tree_method\n",
    "\n",
    "tree_method string [default= auto]\n",
    "\n",
    "The tree construction algorithm used in XGBoost.\n",
    "\n",
    "XGBoost supports approx, hist and gpu_hist for distributed training. Experimental support for external memory is available for approx and gpu_hist.\n",
    "\n",
    "Choices: auto, exact, approx, hist, gpu_hist\n",
    "\n",
    "auto: Use heuristic to choose the fastest method.\n",
    "\n",
    "For small to medium dataset, exact greedy (exact) will be used.\n",
    "\n",
    "For very large dataset, approximate algorithm (approx) will be chosen.\n",
    "\n",
    "Because old behavior is always use exact greedy in single machine, user will get a message when approximate algorithm is chosen to notify this choice.\n",
    "\n",
    "exact: Exact greedy algorithm.\n",
    "\n",
    "approx: Approximate greedy algorithm using quantile sketch and gradient histogram.\n",
    "\n",
    "hist: Fast histogram optimized approximate greedy algorithm. It uses some performance improvements such as bins caching.\n",
    "\n",
    "gpu_hist: GPU implementation of hist algorithm.\n",
    "\n",
    "#### 11. scale_pos_weight\n",
    "\n",
    "scale_pos_weight [default=1]\n",
    "\n",
    "It controls the balance of positive and negative weights,\n",
    "It is useful for imbalanced classes.\n",
    "    A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence.\n",
    "A typical value to consider: sum(negative instances) / sum(positive instances).\n",
    "\n",
    "\n",
    "#### 12. max_leaves\n",
    "\n",
    "max_leaves [default=0]\n",
    "\n",
    "Maximum number of nodes to be added.\n",
    "Only relevant when grow_policy=lossguide is set.\n",
    "There are other hyperparameters like sketch_eps,updater, refresh_leaf, process_type, grow_policy, max_bin, predictor and num_parallel_tree.\n",
    "\n",
    "(source: https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning#2.-XGBoost-hyperparameters- )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48f49387debcf0c5"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "params = { 'model__eta': (0.01, 0.2),\n",
    "           'model__gamma': (0, 5),\n",
    "           'model__max_depth': (3, 10),\n",
    "           'model__min_child_weight': (1, 10),\n",
    "           'model__max_delta_step': (0, 10),\n",
    "           'model__subsample': (0.1,1),\n",
    "           'model__colsample_bytree': (0.5, 1),\n",
    "           'model__colsample_bylevel': (0.5, 1),\n",
    "           'model__colsample_bynode': (0.5, 1),\n",
    "           'model__lambda': (0, 5),\n",
    "           'model__alpha': (0, 5),\n",
    "           'model__scale_pos_weight': (1, 10),\n",
    "           'model__max_leaves': (0, 100)\n",
    "           }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:36:42.404495500Z",
     "start_time": "2023-12-13T15:36:42.394493300Z"
    }
   },
   "id": "4164dcd3c99cb126"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "247b2afa39de24a5"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(pipe, param_distributions=params, n_iter=100, cv=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:36:42.782496500Z",
     "start_time": "2023-12-13T15:36:42.772491100Z"
    }
   },
   "id": "c71625481ade89fb"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"MLflow_hype_tune_random\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # log parameters\n",
    "    mlflow.log_params(random_search.best_params_)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:52:11.047393Z",
     "start_time": "2023-12-13T15:36:43.150492300Z"
    }
   },
   "id": "17ba194dd074a626"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = np.round(random_search.predict(X_test))\n",
    "\n",
    "# metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# metrics logging in  MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(random_search.best_params_)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "    })\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    # Save the plot to a local file\n",
    "    roc_auc_plot_path = \"roc_auc_plot.png\"\n",
    "    plt.savefig(roc_auc_plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Log ROC AUC plot as an artifact\n",
    "    mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:52:11.585787400Z",
     "start_time": "2023-12-13T15:52:11.057395700Z"
    }
   },
   "id": "b5c22fb11d7968b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Greed search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a468301b358c187d"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe,  param_grid=params, cv=5,n_jobs=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:52:11.601788700Z",
     "start_time": "2023-12-13T15:52:11.591789700Z"
    }
   },
   "id": "bd999bff3e4640ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"MLflow_hype_tune_greed\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # log parameters\n",
    "    mlflow.log_params(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-13T15:52:11.605793200Z"
    }
   },
   "id": "b27735339571ee98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = np.round(grid_search.predict(X_test))\n",
    "\n",
    "# metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# metrics logging in  MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "    })\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Save the plot to a local file\n",
    "    roc_auc_plot_path = \"roc_auc_plot.png\"\n",
    "    plt.savefig(roc_auc_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Log ROC AUC plot as an artifact\n",
    "    mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "97c7beae4a4bbf40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dfdd77a3ec8a038c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Функция для оптимизации с помощью Optuna\n",
    "def objective(trial):\n",
    "\n",
    "    # Параметры для оптимизации\n",
    "    params = {\n",
    "        'model__eta': trial.suggest_float('model__eta', 0.01, 0.2),\n",
    "        'model__gamma': trial.suggest_float('model__gamma', 0, 5),\n",
    "        'model__max_depth': trial.suggest_int('model__max_depth', 3, 10),\n",
    "        'model__min_child_weight': trial.suggest_float('model__min_child_weight', 1, 10),\n",
    "        'model__max_delta_step': trial.suggest_float('model__max_delta_step', 0, 10),\n",
    "        'model__subsample': trial.suggest_float('model__subsample', 0.1,1),\n",
    "        'model__colsample_bytree': trial.suggest_float('model__colsample_bytree', 0.5, 1),\n",
    "        'model__colsample_bylevel': trial.suggest_float('model__colsample_bylevel', 0.5, 1),\n",
    "        'model__colsample_bynode': trial.suggest_float('model__colsample_bynode', 0.5, 1),\n",
    "        'model__lambda': trial.suggest_float('model__lambda', 0, 5),\n",
    "        'model__alpha': trial.suggest_float('model__alpha', 0, 5),\n",
    "        'model__scale_pos_weight': trial.suggest_float('model__scale_pos_weight', 1, 10),\n",
    "        'model__max_leaves': trial.suggest_int('model__max_leaves', 0, 100),\n",
    "        #  'model__reg_alpha': trial.suggest_float('model__reg_alpha', 1e-5, 1e2),\n",
    "        # 'model__reg_lambda': trial.suggest_float('model__reg_lambda', 1e-5, 1e2)\n",
    "    }\n",
    "\n",
    "    pipe.set_params(**params)\n",
    "\n",
    "    # Обучение модели\n",
    "    cross_val_mse = cross_val_score(pipe,X_train, y_train).mean()\n",
    "    # pipe.fit(X_train, y_train)\n",
    "\n",
    "    return cross_val_mse\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"MLflow_hype_optuna\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=100)  # Указать желаемое количество итераций\n",
    "\n",
    "    # Get the best trial and its parameters\n",
    "    best_trial = study.best_trial\n",
    "    best_params = best_trial.params\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params(best_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "672484f4ee0c3fc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the best trial and its parameters\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "\n",
    "# Remove the \"model__\" prefix from parameter names\n",
    "cleaned_params = {key.replace(\"model__\", \"\"): value for key, value in best_params.items()}\n",
    "\n",
    "# Set the best parameters to your model\n",
    "pipe.set_params(**best_params)\n",
    "\n",
    "# Train the model with the best parameters on the entire training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = np.round(pipe.predict(X_test))\n",
    "\n",
    "# metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# metrics logging in MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log cleaned parameters\n",
    "    mlflow.log_params(cleaned_params)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "    })\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    # Save the plot to a local file\n",
    "    roc_auc_plot_path = \"roc_auc_plot.png\"\n",
    "    plt.savefig(roc_auc_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Log ROC AUC plot as an artifact\n",
    "    mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot.png\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "53219fd8225fc1c3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDBStorage' object has no attribute '_study_exists'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m study_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMLflow_hype_tune_greed\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Check if the study exists\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m study_exists \u001B[38;5;241m=\u001B[39m \u001B[43mstorage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_study_exists\u001B[49m(study_name)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStudy \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudy_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m exists:\u001B[39m\u001B[38;5;124m\"\u001B[39m, study_exists)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'RDBStorage' object has no attribute '_study_exists'"
     ]
    }
   ],
   "source": [
    "# Provide the correct path to the SQLite database file\n",
    "database_url = \"sqlite:///C:/Users/Peter/DataspellProjects/pythonProject/mlruns/945679505289794617/study.db\"\n",
    "\n",
    "# Create a storage instance\n",
    "storage = optuna.storages.RDBStorage(url=database_url)\n",
    "\n",
    "# Specify the study name\n",
    "study_name = \"MLflow_hype_tune_greed\"\n",
    "\n",
    "# Check if the study exists\n",
    "study_exists = storage._study_exists(study_name)\n",
    "\n",
    "print(f\"Study '{study_name}' exists:\", study_exists)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T17:46:02.531390800Z",
     "start_time": "2023-12-17T17:46:02.412392Z"
    }
   },
   "id": "b25e46b0716cff70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bd4f675e17066294"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
